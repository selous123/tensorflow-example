{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A helper class for managing batch normalization state.                   \n",
    "\n",
    "This class is designed to simplify adding batch normalization               \n",
    "(http://arxiv.org/pdf/1502.03167v3.pdf) to your model by                    \n",
    "managing the state variables associated with it.                            \n",
    "\n",
    "Important use note:  The function get_assigner() returns                    \n",
    "an op that must be executed to save the updated state.                      \n",
    "A suggested way to do this is to make execution of the                      \n",
    "model optimizer force it, e.g., by:                                         \n",
    "\n",
    "  update_assignments = tf.group(bn1.get_assigner(),                         \n",
    "                                bn2.get_assigner())                         \n",
    "  with tf.control_dependencies([optimizer]):                                \n",
    "    optimizer = tf.group(update_assignments)                                \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ConvolutionalBatchNormalizer(object):\n",
    "      \"\"\"Helper class that groups the normalization logic and variables.        \n",
    "\n",
    "      Use:                                                                      \n",
    "          ewma = tf.train.ExponentialMovingAverage(decay=0.99)                  \n",
    "          bn = ConvolutionalBatchNormalizer(depth, 0.001, ewma, True)           \n",
    "          update_assignments = bn.get_assigner()                                \n",
    "          x = bn.normalize(y, train=training?)                                  \n",
    "          (the output x will be batch-normalized).                              \n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self, depth, epsilon, ewma_trainer, scale_after_norm):\n",
    "        self.mean = tf.Variable(tf.constant(0.0, shape=[depth]),\n",
    "                                trainable=False)\n",
    "        self.variance = tf.Variable(tf.constant(1.0, shape=[depth]),\n",
    "                                    trainable=False)\n",
    "        self.beta = tf.Variable(tf.constant(0.0, shape=[depth]))\n",
    "        self.gamma = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "        self.ewma_trainer = ewma_trainer\n",
    "        self.epsilon = epsilon\n",
    "        self.scale_after_norm = scale_after_norm\n",
    "\n",
    "    def get_assigner(self):\n",
    "        \"\"\"Returns an EWMA apply op that must be invoked after optimization.\"\"\"\n",
    "        #在optimization之后必须被调用\n",
    "        return self.ewma_trainer.apply([self.mean, self.variance])\n",
    "\n",
    "    def normalize(self, x, train=True):\n",
    "        \"\"\"Returns a batch-normalized version of x.\"\"\"\n",
    "        if train:\n",
    "            mean, variance = tf.nn.moments(x, [0, 1, 2])\n",
    "            #将mean的值赋值给self.mean\n",
    "            assign_mean = self.mean.assign(mean)\n",
    "            assign_variance = self.variance.assign(variance)\n",
    "            with tf.control_dependencies([assign_mean, assign_variance]):\n",
    "                return tf.nn.batch_normalization(\n",
    "                    x, mean, variance, self.beta, self.gamma,\n",
    "                    self.epsilon, self.scale_after_norm)\n",
    "        else:\n",
    "            mean = self.ewma_trainer.average(self.mean)\n",
    "            variance = self.ewma_trainer.average(self.variance)\n",
    "            local_beta = tf.identity(self.beta)\n",
    "            local_gamma = tf.identity(self.gamma)\n",
    "            return tf.nn.batch_normalization(\n",
    "                x, mean, variance, local_beta, local_gamma,\n",
    "                self.epsilon, self.scale_after_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "w = tf.Variable(1.0,name='w')\n",
    "b = tf.Variable(1.0,name='b')\n",
    "ema = tf.train.ExponentialMovingAverage(0.9)\n",
    "update_w = tf.assign_add(w, 1.0)\n",
    "update_b = tf.assign_sub(b, 0.1)\n",
    "\n",
    "#with tf.control_dependencies([update_w,update_b]):\n",
    "    #返回一个op,这个op用来更新moving_average,i.e. shadow value\n",
    "ema_op = ema.apply([w,b])#这句和下面那句不能调换顺序\n",
    "    #1.adds shadow copies of trained variables\n",
    "    #2.add ops that maintain a moving average of the trained variables\n",
    "\n",
    "# 以 w 当作 key， 获取 shadow value 的值\n",
    "ema_w_val = ema.average(w)#参数不能是list，有点蛋疼\n",
    "#ema_b_val = ema.average(b)\n",
    "tf.summary.scalar(\"w\",ema_w_val)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    if tf.gfile.Exists(\"/tmp/mnist_logs\"):\n",
    "        tf.gfile.DeleteRecursively(\"/tmp/mnist_logs\");\n",
    "    summary_writer = tf.summary.FileWriter('/tmp/mnist_logs',sess.graph)    \n",
    "    \n",
    "    for i in range(3):\n",
    "        sess.run(update_w)\n",
    "        sess.run(ema_op)\n",
    "        #print(sess.run(ema_b_val))\n",
    "        \n",
    "        summary_str = sess.run(merged_summary_op)\n",
    "        summary_writer.add_summary(summary_str, i);\n",
    "    \n",
    "    print(sess.run(ema_w_val))\n",
    "    #print tf.get_collection(tf.GraphKeys.MOVING_AVERAGE_VARIABLES)\n",
    "# 创建一个时间序列 1 2 3 4\n",
    "#输出：\n",
    "#1.1      =0.9*1 + 0.1*2\n",
    "#1.29     =0.9*1.1+0.1*3\n",
    "#1.561    =0.9*1.29+0.1*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.placeholder(dtype=tf.float32,shape=[])\n",
    "op = a.assign(b)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "print(sess.run(a))\n",
    "# 0.0\n",
    "sess.run(op,feed_dict={b:5.})\n",
    "print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.0,name=\"x\")\n",
    "x_plus_1 = tf.assign_add(x, 1)\n",
    "\n",
    "with tf.control_dependencies([x_plus_1]):\n",
    "    y = tf.identity(x)\n",
    "    \n",
    "tf.summary.scalar(\"y\",y)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "if tf.gfile.Exists(\"/tmp/mnist_logs\"):\n",
    "        tf.gfile.DeleteRecursively(\"/tmp/mnist_logs\");\n",
    "with tf.Session() as session:\n",
    "    summary_writer = tf.summary.FileWriter('/tmp/mnist_logs',session.graph)\n",
    "    init.run()\n",
    "    for i in xrange(5):\n",
    "        \n",
    "        summary_str = session.run(merged_summary_op)\n",
    "        summary_writer.add_summary(summary_str,i)\n",
    "        print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.0)\n",
    "x_plus_1 = tf.assign_add(x, 1)\n",
    "\n",
    "with tf.control_dependencies([x_plus_1]):\n",
    "    y = tf.identity(x)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "    for i in xrange(5):\n",
    "        print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "0.19\n",
      "1.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.gfile.Exists(\"/tmp/mnist_logs\"):\n",
    "    tf.gfile.DeleteRecursively(\"/tmp/mnist_logs\");\n",
    "a = tf.Variable(0.1,name='a')\n",
    "b = tf.Variable(0.2,name='b')\n",
    "c = tf.Variable(0.3,name='c')\n",
    "\n",
    "update_a = tf.assign_add(a,1,name='update_a')\n",
    "update_b = tf.assign_sub(b,0.01,name='update_b')\n",
    "update_c = tf.assign_add(c,1,name='update_c')\n",
    "update = tf.group(update_a,update_b,name=\"update_a_b\")\n",
    "with tf.control_dependencies([update_c]):\n",
    "    update_c = tf.group(update,name=\"update_all\")\n",
    "    \n",
    "tf.summary.scalar(\"a\",a)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "summary_writer = tf.summary.FileWriter('/tmp/mnist_logs',session.graph)\n",
    "\n",
    "session.run(update_c)\n",
    "print session.run(a)\n",
    "print session.run(b)\n",
    "print session.run(c)\n",
    "summary_str = session.run(merged_summary_op)\n",
    "summary_writer.add_summary(summary_str,0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
